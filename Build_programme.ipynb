{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d614e56",
   "metadata": {},
   "source": [
    "### Build Environment and Download Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3035e931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.39.3 in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (4.39.3)\n",
      "Requirement already satisfied: filelock in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from transformers==4.39.3) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from transformers==4.39.3) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from transformers==4.39.3) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from transformers==4.39.3) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from transformers==4.39.3) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from transformers==4.39.3) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from transformers==4.39.3) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from transformers==4.39.3) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from transformers==4.39.3) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from transformers==4.39.3) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.3) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.3) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.3) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from requests->transformers==4.39.3) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from requests->transformers==4.39.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from requests->transformers==4.39.3) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages (from requests->transformers==4.39.3) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install -qq faiss-cpu\n",
    "!pip install --upgrade transformers==4.39.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "744db7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import faiss\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b60bc",
   "metadata": {},
   "source": [
    "### Reading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f30b683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"./Data/cls_spam_text_cls.csv\"\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "# Splits messages and label into lists\n",
    "messages = df[\"Message\"].values.tolist()\n",
    "labels = df[\"Category\"].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd6f47",
   "metadata": {},
   "source": [
    "### Preparing embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38f65d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacksonz/Colab Notebooks/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load embedding model\n",
    "MODEL_NAME = \"intfloat/multilingual-e5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def average_pool(last_hidden_states, attention_mask):\n",
    "    last_hidden = last_hidden_states.masked_fill(\n",
    "        ~attention_mask[..., None].bool(), 0.0\n",
    "    )\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5aca838",
   "metadata": {},
   "source": [
    "### Vectorize Data and Generate Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d691c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 175/175 [01:33<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create sentence embeddings\n",
    "def get_embeddings(texts, model, tokenizer, device, batch_size=32):\n",
    "    \"\"\"Create embedding for a list of documents\"\"\"\n",
    "    embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Generating embeddings\"):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_texts_with_prefix = [f\"passage: {text}\" for text in batch_texts]\n",
    "        batch_dict = tokenizer(batch_texts_with_prefix, max_length=512,\n",
    "                               padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        batch_dict = {k: v.to(device) for k,v in batch_dict.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch_dict)\n",
    "            batch_embeddings = average_pool(outputs.last_hidden_state, batch_dict[\"attention_mask\"])\n",
    "            batch_embeddings = F.normalize(batch_embeddings, p=2, dim=1)\n",
    "            embeddings.append(batch_embeddings.cpu().numpy())\n",
    "\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "\n",
    "# Preparing labels    \n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "\n",
    "# Create embeddings for all messages\n",
    "X_embeddings = get_embeddings(messages, model, tokenizer, device)\n",
    "\n",
    "# Creae metadata for each document\n",
    "metadata = [{\"index\": i, \"Message\": message, \"label\": label, \"label_encoded\": y[i]}\n",
    "            for i, (message, label) in enumerate(zip(messages, labels))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1ebf91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 768)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "716f6e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_embeddings[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16efa38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': 2,\n",
       " 'Message': \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       " 'label': 'spam',\n",
       " 'label_encoded': 1}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8ca07",
   "metadata": {},
   "source": [
    "### Building Vector Databases and Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8efb3a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating FAISS index and splitting data\n",
    "TEST_SIZE = 0.1\n",
    "SEED = 42\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(messages)), test_size=TEST_SIZE, stratify=y, random_state=SEED\n",
    ")\n",
    "\n",
    "# Split embeddings and metadata by split index\n",
    "X_train_emb = X_embeddings[train_indices]\n",
    "X_test_emb = X_embeddings[test_indices]\n",
    "train_metadata = [metadata[i] for i in train_indices]\n",
    "test_metadata = [metadata[i] for i in test_indices]\n",
    "\n",
    "# Split labels\n",
    "y_train = [y[i] for i in train_indices]\n",
    "y_test = [y[i] for i in test_indices]\n",
    "\n",
    "# Create FAISS index\n",
    "embedding_dim = X_train_emb.shape[1]\n",
    "index = faiss.IndexFlatIP(embedding_dim)\n",
    "index.add(X_train_emb.astype(\"float32\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a57886d",
   "metadata": {},
   "source": [
    "### Building Classification and Evaluation Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f285a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing classification with embedding similarity\n",
    "def classify_with_knn(query_text, model, tokenizer, device, index, train_metadata, k=1):\n",
    "\n",
    "    \"\"\"Classify text using k-nearnest neighbors with embeddings\"\"\"\n",
    "\n",
    "    # Get query embedding\n",
    "    query_with_prefix = f\"query: {query_text}\"\n",
    "    batch_dict = tokenizer([query_with_prefix],\n",
    "                           max_length=512,\n",
    "                           padding=True,\n",
    "                           truncation=True,\n",
    "                           return_tensors=\"pt\")\n",
    "    \n",
    "    batch_dict = {k: v.to(device) for k, v in batch_dict.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch_dict)\n",
    "        query_embedding = average_pool(outputs.last_hidden_state, batch_dict[\"attention_mask\"])\n",
    "        query_embedding = F.normalize(query_embedding, p=2, dim=1)\n",
    "        query_embedding = query_embedding.cpu().numpy().astype(\"float32\")\n",
    "\n",
    "    # Search in FAISS index\n",
    "    scores, indices = index.search(query_embedding, k)\n",
    "\n",
    "    # Get predictions from top-k neighbors\n",
    "    predictions = []\n",
    "    neighbor_info = []\n",
    "\n",
    "    for i in range(k):\n",
    "        neighbor_idx = indices[0][i]\n",
    "        neighbor_score = scores[0][i]\n",
    "        neighbor_label = train_metadata[neighbor_idx][\"label\"]\n",
    "        neighbor_message = train_metadata[neighbor_idx][\"Message\"]\n",
    "\n",
    "        predictions.append(neighbor_label)\n",
    "        neighbor_info.append({\n",
    "            \"score\": float(neighbor_score),\n",
    "            \"label\": neighbor_label,\n",
    "            \"message\": neighbor_message[:100] + \"...\" if len(neighbor_message) > 100 else neighbor_message\n",
    "        })\n",
    "\n",
    "    # Majority vote for final prediction\n",
    "    unique_labels, counts = np.unique(predictions, return_counts=True)\n",
    "    final_prediction = unique_labels[np.argmax(counts)]\n",
    "    return final_prediction, neighbor_info\n",
    "\n",
    "def evaluate_knn_accuracy(test_embeddings, test_labels, test_metadata, index,\n",
    "                          train_metadata, k_values=[1, 3, 5]):\n",
    "    \"\"\"\n",
    "    Evaluate accuracy for different k values using precomputed embeddings\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    all_errors = {}\n",
    "\n",
    "    for k in k_values:\n",
    "        correct = 0\n",
    "        total = len(test_embeddings)\n",
    "        errors = []\n",
    "\n",
    "        for i in tqdm(range(total), desc=f\"Evaluating k={k}\"):\n",
    "            query_embedding = test_embeddings[i:i+1].astype(\"float32\")\n",
    "            true_label = test_metadata[i][\"label\"]\n",
    "            true_message = test_metadata[i][\"Message\"]\n",
    "\n",
    "            # Search in FAISS index\n",
    "            scores, indices = index.search(query_embedding, k)\n",
    "\n",
    "            # Get predictions from top-k neighbors\n",
    "            predictions = []\n",
    "            neighbor_details = []\n",
    "            for j in range(k):\n",
    "                neighbor_idx = indices[0][j]\n",
    "                neighbor_label = train_metadata[neighbor_idx][\"label\"]\n",
    "                neighbor_message = train_metadata[neighbor_idx][\"Message\"]\n",
    "                neighbor_score = float(scores[0][j])\n",
    "\n",
    "                predictions.append(neighbor_label)\n",
    "                neighbor_details.append({\n",
    "                    \"label\": neighbor_label,\n",
    "                    \"message\": neighbor_message,\n",
    "                    \"score\": neighbor_score\n",
    "                })\n",
    "            \n",
    "            # Majority vote\n",
    "            unique_labels, counts = np.unique(predictions, return_counts=True)\n",
    "            predicted_label = unique_labels[np.argmax(counts)]\n",
    "\n",
    "            if predicted_label == true_label:\n",
    "                correct += 1\n",
    "            else:\n",
    "                # Collect error information\n",
    "                error_info = {\n",
    "                    \"index\": i,\n",
    "                    \"original_index\": test_metadata[i][\"index\"],\n",
    "                    \"message\": true_message,\n",
    "                    \"true_label\": true_label,\n",
    "                    \"predicted_label\": predicted_label,\n",
    "                    \"neighbors\": neighbor_details,\n",
    "                    \"label_distribution\": {label: int(count) for label, count in zip(unique_labels, counts)}\n",
    "                }\n",
    "                errors.append(error_info)\n",
    "\n",
    "        accuracy = correct / total\n",
    "        error_count = total - correct\n",
    "\n",
    "        results[k] = accuracy\n",
    "        all_errors[k] = errors\n",
    "\n",
    "        print(f\"Accuracy with k={k}: {accuracy:.4f}\")\n",
    "        print(f\"Number of errors with k={k}: {error_count}/{total} ({(error_count/total)*100:.2f}%)\")\n",
    "\n",
    "    return results, all_errors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc143b8",
   "metadata": {},
   "source": [
    "### Model Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b50ff5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating accuracy on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating k=1: 100%|██████████| 558/558 [00:00<00:00, 2916.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k=1: 0.9857\n",
      "Number of errors with k=1: 8/558 (1.43%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating k=3: 100%|██████████| 558/558 [00:00<00:00, 2881.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k=3: 0.9928\n",
      "Number of errors with k=3: 4/558 (0.72%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating k=5: 100%|██████████| 558/558 [00:00<00:00, 2988.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k=5: 0.9910\n",
      "Number of errors with k=5: 5/558 (0.90%)\n",
      "\n",
      "Evaluation completed in 0.58 seconds\n",
      "\n",
      "==================================================\n",
      "ACCURACY RESULTS\n",
      "==================================================\n",
      "Top-1 accuracy: 0.9857 (98.57%)\n",
      "Top-3 accuracy: 0.9928 (99.28%)\n",
      "Top-5 accuracy: 0.9910 (99.10%)\n",
      "==================================================\n",
      "\n",
      "***Error analysis saved to: error_analysis.json***\n",
      "\n",
      "***Summary:\n",
      "  k=1: 8 errors out of 558 samples\n",
      "  k=3: 4 errors out of 558 samples\n",
      "  k=5: 5 errors out of 558 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Evaluation on test set\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Evaluating accuracy on test set...\")\n",
    "accuracy_results, error_results = evaluate_knn_accuracy(\n",
    "    X_test_emb,\n",
    "    y_test,\n",
    "    test_metadata,\n",
    "    index,\n",
    "    train_metadata,\n",
    "    k_values=[1, 3, 5]\n",
    ")\n",
    "\n",
    "# Show results\n",
    "end_time = time.time()\n",
    "print(f\"\\nEvaluation completed in {end_time - start_time:.2f} seconds\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ACCURACY RESULTS\")\n",
    "print(\"=\"*50)\n",
    "for k, accuracy in accuracy_results.items():\n",
    "    print(f\"Top-{k} accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Save error analysis to file\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "error_analysis = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"test_size\": len(X_test_emb),\n",
    "    \"accuracy_results\": accuracy_results,\n",
    "    \"errors_by_k\": {}\n",
    "}\n",
    "\n",
    "for k, errors in error_results.items():\n",
    "    error_analysis[\"errors_by_k\"][f\"k={k}\"] = {\n",
    "        \"total_errors\": len(errors),\n",
    "        \"error_rate\": len(errors) / len(X_test_emb),\n",
    "        \"errors\": errors\n",
    "    }\n",
    "\n",
    "# Save JSON file with error log\n",
    "output_file = \"error_analysis.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(error_analysis, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n***Error analysis saved to: {output_file}***\")\n",
    "print(\"\\n***Summary:\")\n",
    "for k, errors in error_results.items():\n",
    "    print(f\"  k={k}: {len(errors)} errors out of {len(X_test_emb)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc82e62",
   "metadata": {},
   "source": [
    "### Build a Complete Classification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "804ee641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline classification cho user input\n",
    "def spam_classifier_pipeline(user_input, k=3):\n",
    "    \"\"\"\n",
    "    Complete pipeline for spam classification\n",
    "\n",
    "    Args:\n",
    "        user_input (str): Text to classify\n",
    "        k (int): Number of nearest neighbors to consider\n",
    "\n",
    "    Returns:\n",
    "        dict: Classification results with details\n",
    "    \"\"\"\n",
    "    print()\n",
    "    print(f\"***Classifying: \\\"{user_input}\\\"\")\n",
    "    print()\n",
    "    print(f\"***Using top-{k} nearest neighbors\")\n",
    "    print()\n",
    "\n",
    "    # Get prediction and neighbors\n",
    "    prediction, neighbors = classify_with_knn(\n",
    "        user_input, model, tokenizer, device, index, train_metadata, k=k\n",
    "    )\n",
    "\n",
    "    # Display results\n",
    "    print(f\"***Prediction: {prediction.upper()}\")\n",
    "    print()\n",
    "\n",
    "    print(\"***Top neighbors:\")\n",
    "    for i, neighbor in enumerate(neighbors, 1):\n",
    "        print(f\"{i}. Label: {neighbor['label']} | Score: {neighbor['score']:.4f}\")\n",
    "        print(f\"   Message: {neighbor['message']}\")\n",
    "        print()\n",
    "\n",
    "    # Count label distribution\n",
    "    labels = [n[\"label\"] for n in neighbors]\n",
    "    label_counts = {label: labels.count(label) for label in set(labels)}\n",
    "\n",
    "    return {\n",
    "        \"prediction\": prediction,\n",
    "        \"neighbors\": neighbors,\n",
    "        \"label_distribution\": label_counts\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801251e8",
   "metadata": {},
   "source": [
    "### Pipeline Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a8ec6b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 1: \"I am actually thinking a way of doing something useful\" ---\n",
      "\n",
      "***Classifying: \"I am actually thinking a way of doing something useful\"\n",
      "\n",
      "***Using top-3 nearest neighbors\n",
      "\n",
      "***Prediction: HAM\n",
      "\n",
      "***Top neighbors:\n",
      "1. Label: ham | Score: 0.8424\n",
      "   Message: yeah, that's what I was thinking\n",
      "\n",
      "2. Label: ham | Score: 0.8412\n",
      "   Message: that would be good … I'll phone you tomo lunchtime, shall I, to organise something?\n",
      "\n",
      "3. Label: ham | Score: 0.8344\n",
      "   Message: See? I thought it all through\n",
      "\n",
      "\n",
      "--- Example 2: \"FREE!! Click here to win \\$1000 NOW! Limited time offer!\" ---\n",
      "\n",
      "***Classifying: \"FREE!! Click here to win \\$1000 NOW! Limited time offer!\"\n",
      "\n",
      "***Using top-3 nearest neighbors\n",
      "\n",
      "***Prediction: SPAM\n",
      "\n",
      "***Top neighbors:\n",
      "1. Label: spam | Score: 0.8566\n",
      "   Message: Win a £1000 cash prize or a prize worth £5000\n",
      "\n",
      "2. Label: spam | Score: 0.8499\n",
      "   Message: FREE entry into our £250 weekly competition just text the word WIN to 80086 NOW. 18 T&C www.txttowin...\n",
      "\n",
      "3. Label: spam | Score: 0.8489\n",
      "   Message: FREE MESSAGE Activate your 500 FREE Text Messages by replying to this message with the word FREE For...\n",
      "\n",
      "\n",
      "--- Interactive Testing ---\n",
      "\n",
      "***Classifying: \"Win a free iPhone! Click here now!\"\n",
      "\n",
      "***Using top-5 nearest neighbors\n",
      "\n",
      "***Prediction: SPAM\n",
      "\n",
      "***Top neighbors:\n",
      "1. Label: spam | Score: 0.8633\n",
      "   Message: FREE entry into our £250 weekly competition just text the word WIN to 80086 NOW. 18 T&C www.txttowin...\n",
      "\n",
      "2. Label: spam | Score: 0.8604\n",
      "   Message: FREE MESSAGE Activate your 500 FREE Text Messages by replying to this message with the word FREE For...\n",
      "\n",
      "3. Label: spam | Score: 0.8604\n",
      "   Message: FREE MESSAGE Activate your 500 FREE Text Messages by replying to this message with the word FREE For...\n",
      "\n",
      "4. Label: spam | Score: 0.8511\n",
      "   Message: U have won a nokia 6230 plus a free digital camera. This is what u get when u win our FREE auction. ...\n",
      "\n",
      "5. Label: spam | Score: 0.8507\n",
      "   Message: TheMob>Yo yo yo-Here comes a new selection of hot downloads for our members to get for FREE! Just cl...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test pipeline with different examples\n",
    "test_examples = [\n",
    "    \"I am actually thinking a way of doing something useful\",\n",
    "    \"FREE!! Click here to win \\$1000 NOW! Limited time offer!\",\n",
    "]\n",
    "\n",
    "for i, example in enumerate(test_examples, 1):\n",
    "    print(f\"\\n--- Example {i}: \\\"{example}\\\" ---\")\n",
    "    result = spam_classifier_pipeline(example, k=3)\n",
    "\n",
    "# Interactive testing – người dùng có thể thay đổi text và k value\n",
    "print(\"\\n--- Interactive Testing ---\")\n",
    "user_text = \"Win a free iPhone! Click here now!\"\n",
    "k_value = 5\n",
    "result = spam_classifier_pipeline(user_text, k=k_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f57328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
